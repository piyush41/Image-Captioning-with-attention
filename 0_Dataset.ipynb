{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "#sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "# initialize COCO API for instance annotations\n",
    "dataDir = os.getcwd()\n",
    "dataType = 'val2014'\n",
    "instances_annFile = os.path.join(dataDir, 'annotations', 'instances_{}.json'.format(dataType))\n",
    "coco = COCO(instances_annFile)\n",
    "\n",
    "# initialize COCO API for caption annotations\n",
    "captions_annFile = os.path.join(dataDir, 'annotations', 'instances_{}.json'.format(dataType))\n",
    "coco_caps = COCO(captions_annFile)\n",
    "\n",
    "# get image ids \n",
    "ids = list(coco.anns.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Plot a Sample Image\n",
    "\n",
    "Next, we plot a random image from the dataset, along with its five corresponding captions.  Each time you run the code cell below, a different image is selected.  \n",
    "\n",
    "In the project, you will use this dataset to train your own model to generate captions from images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The length of image dataset:',len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Example of an image annotation:', coco.anns[649222])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# pick a random image and obtain the corresponding URL\n",
    "ann_id = np.random.choice(ids)\n",
    "img_id = coco.anns[ann_id]['image_id']\n",
    "img = coco.loadImgs(img_id)[0]\n",
    "url = img['coco_url']\n",
    "\n",
    "# print URL and visualize corresponding image\n",
    "print(url)\n",
    "I = io.imread(url)\n",
    "plt.axis('off')\n",
    "plt.imshow(I)\n",
    "plt.show()\n",
    "\n",
    "# load and display captions\n",
    "annIds = coco_caps.getAnnIds(imgIds=img['id']);\n",
    "anns = coco_caps.loadAnns(annIds)\n",
    "coco_caps.showAnns(anns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > ### Notes on `pycocotools.coco`\n",
    " According to https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocotools/coco.py\n",
    " * `COCO` is Constructor of Microsoft COCO helper class for reading and visualizing annotations.\n",
    " * `.anns[idx]` - contains full annotation of specific image, including task (e.g. segmentation), bounding box, image_id, category_id and so on.\n",
    " * `.loadImgs(image_id)` - load particular annotation with the specified id, that includes image URL and other image attributes.\n",
    " * `annIds = coco_caps.getAnnIds(imgIds=img['id'])`- get ids of annotations.\n",
    " * `coco_caps.loadAnns(annIds)` - load annotations based on ids gotten from previous function.\n",
    " * `.showAnns()` - display annotations (captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: What's to Come!\n",
    "\n",
    "In this project, you will use the dataset of image-caption pairs to train a CNN-RNN model to automatically generate images from captions.  You'll learn more about how to design the architecture in the next notebook in the sequence (**1_Preliminaries.ipynb**).\n",
    "\n",
    "![Image Captioning CNN-RNN model](images/encoder-decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
